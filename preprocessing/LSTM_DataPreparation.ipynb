{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0bdea6-661f-47de-837c-584e90f9ab70",
   "metadata": {},
   "source": [
    "# LSTM Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac9c138-f27e-4f6e-912b-ea106b81cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicts the next category based on a block of 5 categories as window\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4344fa14-1dd4-49b8-baef-ae53b362bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb1ec34-2e68-4e01-bf24-ce769b4e7375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>taps</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>appIds0</th>\n",
       "      <th>tapsSession</th>\n",
       "      <th>lengthSession</th>\n",
       "      <th>partId</th>\n",
       "      <th>timeZone</th>\n",
       "      <th>tapDeviceId</th>\n",
       "      <th>category</th>\n",
       "      <th>application</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00e98a60-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260654282', '1680260656216']</td>\n",
       "      <td>[1.68026065e+12]</td>\n",
       "      <td>[1.68026068e+12]</td>\n",
       "      <td>['4', '6']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1934]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['-1', 'COMMUNICATION']</td>\n",
       "      <td>['com.miui.home', 'com.whatsapp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00e9b170-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260848742', '1680260849767', '1680260850...</td>\n",
       "      <td>[1.68026085e+12]</td>\n",
       "      <td>[1.6802609e+12]</td>\n",
       "      <td>['6', '6', '6', '6', '6', '6', '6', '6', '6', ...</td>\n",
       "      <td>[91]</td>\n",
       "      <td>[51590]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp', 'com.whatsapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ea26a0-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260926555', '1680260929904']</td>\n",
       "      <td>[1.68026092e+12]</td>\n",
       "      <td>[1.68026094e+12]</td>\n",
       "      <td>['6', '6']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3349]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION']</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00ea26a1-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260966773']</td>\n",
       "      <td>[1.68026097e+12]</td>\n",
       "      <td>[1.68026097e+12]</td>\n",
       "      <td>['6']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION']</td>\n",
       "      <td>['com.whatsapp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00ea4db0-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680261384529', '1680261386184', '1680261386...</td>\n",
       "      <td>[1.68026138e+12]</td>\n",
       "      <td>[1.6802614e+12]</td>\n",
       "      <td>['6', '6', '6', '6', '6', '6', '6', '6', '6', ...</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[12116]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp', 'com.whatsapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144357</th>\n",
       "      <td>ffe7d2ba-50e8-4d98-a57e-e7fb66d1daf0</td>\n",
       "      <td>['']</td>\n",
       "      <td>[1.6873238e+12]</td>\n",
       "      <td>[1.6873238e+12]</td>\n",
       "      <td>['']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['138e0aa217a29b6e43b191d55547762fb7bc28eb']</td>\n",
       "      <td>['Asia/Kathmandu']</td>\n",
       "      <td>['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144358</th>\n",
       "      <td>190f1650-3360-4014-b441-3963eb982f96</td>\n",
       "      <td>['', '']</td>\n",
       "      <td>[1.68571532e+12]</td>\n",
       "      <td>[1.68571533e+12]</td>\n",
       "      <td>['', '']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['138e4fc6a0c3f9c84a748783729e965d586628eb']</td>\n",
       "      <td>['Europe/Rome']</td>\n",
       "      <td>['01e797d4-2d69-4a04-abad-0f53de6eb216']</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144359</th>\n",
       "      <td>33da6d62-a24b-4fac-911e-5210163999d8</td>\n",
       "      <td>['1685715102620', '1685715103191', '1685715104...</td>\n",
       "      <td>[1.6857151e+12]</td>\n",
       "      <td>[1.68571531e+12]</td>\n",
       "      <td>['1', '1', '4', '1', '1', '3', '3', '3', '3', ...</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[198617]</td>\n",
       "      <td>['138e4fc6a0c3f9c84a748783729e965d586628eb']</td>\n",
       "      <td>['Europe/Rome']</td>\n",
       "      <td>['01e797d4-2d69-4a04-abad-0f53de6eb216']</td>\n",
       "      <td>['PERSONALIZATION', 'PERSONALIZATION', '-1', '...</td>\n",
       "      <td>['com.sec.android.app.launcher', 'com.sec.andr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144360</th>\n",
       "      <td>7747522b-63d2-4dfd-9bf2-61010e8966f7</td>\n",
       "      <td>['', '']</td>\n",
       "      <td>[1.68571539e+12]</td>\n",
       "      <td>[1.68571541e+12]</td>\n",
       "      <td>['', '']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['138e4fc6a0c3f9c84a748783729e965d586628eb']</td>\n",
       "      <td>['Europe/Rome']</td>\n",
       "      <td>['01e797d4-2d69-4a04-abad-0f53de6eb216']</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144361</th>\n",
       "      <td>785b109d-5bab-4243-91bb-7f7bf6b2b1af</td>\n",
       "      <td>['1685715937398', '1685715947273', '1685715958...</td>\n",
       "      <td>[1.68571592e+12]</td>\n",
       "      <td>[1.68571624e+12]</td>\n",
       "      <td>['6', '6', '6', '6', '6', '6', '6', '6', '6', ...</td>\n",
       "      <td>[230]</td>\n",
       "      <td>[302285]</td>\n",
       "      <td>['138e4fc6a0c3f9c84a748783729e965d586628eb']</td>\n",
       "      <td>['Europe/Rome']</td>\n",
       "      <td>['01e797d4-2d69-4a04-abad-0f53de6eb216']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp', 'com.whatsapp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144362 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id  \\\n",
       "0       00e98a60-cfbc-11ed-a03c-bf72362c36e7   \n",
       "1       00e9b170-cfbc-11ed-a03c-bf72362c36e7   \n",
       "2       00ea26a0-cfbc-11ed-a03c-bf72362c36e7   \n",
       "3       00ea26a1-cfbc-11ed-a03c-bf72362c36e7   \n",
       "4       00ea4db0-cfbc-11ed-a03c-bf72362c36e7   \n",
       "...                                      ...   \n",
       "144357  ffe7d2ba-50e8-4d98-a57e-e7fb66d1daf0   \n",
       "144358  190f1650-3360-4014-b441-3963eb982f96   \n",
       "144359  33da6d62-a24b-4fac-911e-5210163999d8   \n",
       "144360  7747522b-63d2-4dfd-9bf2-61010e8966f7   \n",
       "144361  785b109d-5bab-4243-91bb-7f7bf6b2b1af   \n",
       "\n",
       "                                                     taps             start  \\\n",
       "0                      ['1680260654282', '1680260656216']  [1.68026065e+12]   \n",
       "1       ['1680260848742', '1680260849767', '1680260850...  [1.68026085e+12]   \n",
       "2                      ['1680260926555', '1680260929904']  [1.68026092e+12]   \n",
       "3                                       ['1680260966773']  [1.68026097e+12]   \n",
       "4       ['1680261384529', '1680261386184', '1680261386...  [1.68026138e+12]   \n",
       "...                                                   ...               ...   \n",
       "144357                                               ['']   [1.6873238e+12]   \n",
       "144358                                           ['', '']  [1.68571532e+12]   \n",
       "144359  ['1685715102620', '1685715103191', '1685715104...   [1.6857151e+12]   \n",
       "144360                                           ['', '']  [1.68571539e+12]   \n",
       "144361  ['1685715937398', '1685715947273', '1685715958...  [1.68571592e+12]   \n",
       "\n",
       "                    stop                                            appIds0  \\\n",
       "0       [1.68026068e+12]                                         ['4', '6']   \n",
       "1        [1.6802609e+12]  ['6', '6', '6', '6', '6', '6', '6', '6', '6', ...   \n",
       "2       [1.68026094e+12]                                         ['6', '6']   \n",
       "3       [1.68026097e+12]                                              ['6']   \n",
       "4        [1.6802614e+12]  ['6', '6', '6', '6', '6', '6', '6', '6', '6', ...   \n",
       "...                  ...                                                ...   \n",
       "144357   [1.6873238e+12]                                               ['']   \n",
       "144358  [1.68571533e+12]                                           ['', '']   \n",
       "144359  [1.68571531e+12]  ['1', '1', '4', '1', '1', '3', '3', '3', '3', ...   \n",
       "144360  [1.68571541e+12]                                           ['', '']   \n",
       "144361  [1.68571624e+12]  ['6', '6', '6', '6', '6', '6', '6', '6', '6', ...   \n",
       "\n",
       "       tapsSession lengthSession  \\\n",
       "0              [2]        [1934]   \n",
       "1             [91]       [51590]   \n",
       "2              [2]        [3349]   \n",
       "3              [1]           [0]   \n",
       "4             [34]       [12116]   \n",
       "...            ...           ...   \n",
       "144357         [0]           [0]   \n",
       "144358         [0]           [0]   \n",
       "144359        [18]      [198617]   \n",
       "144360         [0]           [0]   \n",
       "144361       [230]      [302285]   \n",
       "\n",
       "                                              partId            timeZone  \\\n",
       "0       ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   ['Europe/Vienna']   \n",
       "1       ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   ['Europe/Vienna']   \n",
       "2       ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   ['Europe/Vienna']   \n",
       "3       ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   ['Europe/Vienna']   \n",
       "4       ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   ['Europe/Vienna']   \n",
       "...                                              ...                 ...   \n",
       "144357  ['138e0aa217a29b6e43b191d55547762fb7bc28eb']  ['Asia/Kathmandu']   \n",
       "144358  ['138e4fc6a0c3f9c84a748783729e965d586628eb']     ['Europe/Rome']   \n",
       "144359  ['138e4fc6a0c3f9c84a748783729e965d586628eb']     ['Europe/Rome']   \n",
       "144360  ['138e4fc6a0c3f9c84a748783729e965d586628eb']     ['Europe/Rome']   \n",
       "144361  ['138e4fc6a0c3f9c84a748783729e965d586628eb']     ['Europe/Rome']   \n",
       "\n",
       "                                     tapDeviceId  \\\n",
       "0       ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "1       ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "2       ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "3       ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "4       ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "...                                          ...   \n",
       "144357  ['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']   \n",
       "144358  ['01e797d4-2d69-4a04-abad-0f53de6eb216']   \n",
       "144359  ['01e797d4-2d69-4a04-abad-0f53de6eb216']   \n",
       "144360  ['01e797d4-2d69-4a04-abad-0f53de6eb216']   \n",
       "144361  ['01e797d4-2d69-4a04-abad-0f53de6eb216']   \n",
       "\n",
       "                                                 category  \\\n",
       "0                                 ['-1', 'COMMUNICATION']   \n",
       "1       ['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...   \n",
       "2                      ['COMMUNICATION', 'COMMUNICATION']   \n",
       "3                                       ['COMMUNICATION']   \n",
       "4       ['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...   \n",
       "...                                                   ...   \n",
       "144357                                             [None]   \n",
       "144358                                       [None, None]   \n",
       "144359  ['PERSONALIZATION', 'PERSONALIZATION', '-1', '...   \n",
       "144360                                       [None, None]   \n",
       "144361  ['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...   \n",
       "\n",
       "                                              application  \n",
       "0                       ['com.miui.home', 'com.whatsapp']  \n",
       "1       ['com.whatsapp', 'com.whatsapp', 'com.whatsapp...  \n",
       "2                        ['com.whatsapp', 'com.whatsapp']  \n",
       "3                                        ['com.whatsapp']  \n",
       "4       ['com.whatsapp', 'com.whatsapp', 'com.whatsapp...  \n",
       "...                                                   ...  \n",
       "144357                                             [None]  \n",
       "144358                                       [None, None]  \n",
       "144359  ['com.sec.android.app.launcher', 'com.sec.andr...  \n",
       "144360                                       [None, None]  \n",
       "144361  ['com.whatsapp', 'com.whatsapp', 'com.whatsapp...  \n",
       "\n",
       "[144362 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Uploads\n",
    "tap_data = pd.read_csv('TapDataParsed_processed.csv', usecols=lambda column: column not in ['Unnamed: 0'])\n",
    "tap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c798992e-6643-4d5b-a22d-996b9da3cf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_ids = len(list(tap_data['partId'].unique()))\n",
    "part_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5406f3f0-dea9-4b29-928f-6495e4cc44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty taps [['', '']]\n",
    "tap_data = tap_data[tap_data['taps'].apply(lambda x: x != \"['', '']\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "244a118f-af09-4077-aeb0-4ffc5b89d229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>taps</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>appIds0</th>\n",
       "      <th>tapsSession</th>\n",
       "      <th>lengthSession</th>\n",
       "      <th>partId</th>\n",
       "      <th>timeZone</th>\n",
       "      <th>tapDeviceId</th>\n",
       "      <th>category</th>\n",
       "      <th>application</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00e98a60-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260654282', '1680260656216']</td>\n",
       "      <td>[1.68026065e+12]</td>\n",
       "      <td>[1.68026068e+12]</td>\n",
       "      <td>['4', '6']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1934]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['-1', 'COMMUNICATION']</td>\n",
       "      <td>['com.miui.home', 'com.whatsapp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00e9b170-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260848742', '1680260849767', '1680260850...</td>\n",
       "      <td>[1.68026085e+12]</td>\n",
       "      <td>[1.6802609e+12]</td>\n",
       "      <td>['6', '6', '6', '6', '6', '6', '6', '6', '6', ...</td>\n",
       "      <td>[91]</td>\n",
       "      <td>[51590]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp', 'com.whatsapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ea26a0-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260926555', '1680260929904']</td>\n",
       "      <td>[1.68026092e+12]</td>\n",
       "      <td>[1.68026094e+12]</td>\n",
       "      <td>['6', '6']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3349]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION']</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00ea26a1-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680260966773']</td>\n",
       "      <td>[1.68026097e+12]</td>\n",
       "      <td>[1.68026097e+12]</td>\n",
       "      <td>['6']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION']</td>\n",
       "      <td>['com.whatsapp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00ea4db0-cfbc-11ed-a03c-bf72362c36e7</td>\n",
       "      <td>['1680261384529', '1680261386184', '1680261386...</td>\n",
       "      <td>[1.68026138e+12]</td>\n",
       "      <td>[1.6802614e+12]</td>\n",
       "      <td>['6', '6', '6', '6', '6', '6', '6', '6', '6', ...</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[12116]</td>\n",
       "      <td>['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']</td>\n",
       "      <td>['Europe/Vienna']</td>\n",
       "      <td>['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp', 'com.whatsapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66888</th>\n",
       "      <td>fea3361e-f3a7-42e2-aa9c-29b7c13d2fc8</td>\n",
       "      <td>['1688567611127', '1688567611634']</td>\n",
       "      <td>[1.68856761e+12]</td>\n",
       "      <td>[1.68856761e+12]</td>\n",
       "      <td>['4', '4']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[507]</td>\n",
       "      <td>['138e0aa217a29b6e43b191d55547762fb7bc28eb']</td>\n",
       "      <td>['Asia/Kathmandu']</td>\n",
       "      <td>['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']</td>\n",
       "      <td>['-1', '-1']</td>\n",
       "      <td>['com.oppo.launcher', 'com.oppo.launcher']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66889</th>\n",
       "      <td>fec83b19-38e1-4685-a8cd-fb8a63b4b9b7</td>\n",
       "      <td>['1687686629107', '1687686630650', '1687686632...</td>\n",
       "      <td>[1.68768662e+12]</td>\n",
       "      <td>[1.68768686e+12]</td>\n",
       "      <td>['25', '25', '25', '25', '25', '25', '25', '25...</td>\n",
       "      <td>[55]</td>\n",
       "      <td>[232127]</td>\n",
       "      <td>['138e0aa217a29b6e43b191d55547762fb7bc28eb']</td>\n",
       "      <td>['Asia/Kathmandu']</td>\n",
       "      <td>['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']</td>\n",
       "      <td>['SOCIAL', 'SOCIAL', 'SOCIAL', 'SOCIAL', 'SOCI...</td>\n",
       "      <td>['com.zhiliaoapp.musically', 'com.zhiliaoapp.m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66890</th>\n",
       "      <td>fefc5f0a-ae06-495b-9ab8-bc5d55a6c37a</td>\n",
       "      <td>['1688194591567', '1688194595574', '1688194602...</td>\n",
       "      <td>[1.68819459e+12]</td>\n",
       "      <td>[1.6881949e+12]</td>\n",
       "      <td>['4', '36', '36', '36', '36', '36', '36', '36'...</td>\n",
       "      <td>[72]</td>\n",
       "      <td>[302195]</td>\n",
       "      <td>['138e0aa217a29b6e43b191d55547762fb7bc28eb']</td>\n",
       "      <td>['Asia/Kathmandu']</td>\n",
       "      <td>['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']</td>\n",
       "      <td>['-1', 'SOCIAL', 'SOCIAL', 'SOCIAL', 'SOCIAL',...</td>\n",
       "      <td>['com.oppo.launcher', 'com.instagram.android',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66891</th>\n",
       "      <td>33da6d62-a24b-4fac-911e-5210163999d8</td>\n",
       "      <td>['1685715102620', '1685715103191', '1685715104...</td>\n",
       "      <td>[1.6857151e+12]</td>\n",
       "      <td>[1.68571531e+12]</td>\n",
       "      <td>['1', '1', '4', '1', '1', '3', '3', '3', '3', ...</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[198617]</td>\n",
       "      <td>['138e4fc6a0c3f9c84a748783729e965d586628eb']</td>\n",
       "      <td>['Europe/Rome']</td>\n",
       "      <td>['01e797d4-2d69-4a04-abad-0f53de6eb216']</td>\n",
       "      <td>['PERSONALIZATION', 'PERSONALIZATION', '-1', '...</td>\n",
       "      <td>['com.sec.android.app.launcher', 'com.sec.andr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66892</th>\n",
       "      <td>785b109d-5bab-4243-91bb-7f7bf6b2b1af</td>\n",
       "      <td>['1685715937398', '1685715947273', '1685715958...</td>\n",
       "      <td>[1.68571592e+12]</td>\n",
       "      <td>[1.68571624e+12]</td>\n",
       "      <td>['6', '6', '6', '6', '6', '6', '6', '6', '6', ...</td>\n",
       "      <td>[230]</td>\n",
       "      <td>[302285]</td>\n",
       "      <td>['138e4fc6a0c3f9c84a748783729e965d586628eb']</td>\n",
       "      <td>['Europe/Rome']</td>\n",
       "      <td>['01e797d4-2d69-4a04-abad-0f53de6eb216']</td>\n",
       "      <td>['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...</td>\n",
       "      <td>['com.whatsapp', 'com.whatsapp', 'com.whatsapp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66893 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0      00e98a60-cfbc-11ed-a03c-bf72362c36e7   \n",
       "1      00e9b170-cfbc-11ed-a03c-bf72362c36e7   \n",
       "2      00ea26a0-cfbc-11ed-a03c-bf72362c36e7   \n",
       "3      00ea26a1-cfbc-11ed-a03c-bf72362c36e7   \n",
       "4      00ea4db0-cfbc-11ed-a03c-bf72362c36e7   \n",
       "...                                     ...   \n",
       "66888  fea3361e-f3a7-42e2-aa9c-29b7c13d2fc8   \n",
       "66889  fec83b19-38e1-4685-a8cd-fb8a63b4b9b7   \n",
       "66890  fefc5f0a-ae06-495b-9ab8-bc5d55a6c37a   \n",
       "66891  33da6d62-a24b-4fac-911e-5210163999d8   \n",
       "66892  785b109d-5bab-4243-91bb-7f7bf6b2b1af   \n",
       "\n",
       "                                                    taps             start  \\\n",
       "0                     ['1680260654282', '1680260656216']  [1.68026065e+12]   \n",
       "1      ['1680260848742', '1680260849767', '1680260850...  [1.68026085e+12]   \n",
       "2                     ['1680260926555', '1680260929904']  [1.68026092e+12]   \n",
       "3                                      ['1680260966773']  [1.68026097e+12]   \n",
       "4      ['1680261384529', '1680261386184', '1680261386...  [1.68026138e+12]   \n",
       "...                                                  ...               ...   \n",
       "66888                 ['1688567611127', '1688567611634']  [1.68856761e+12]   \n",
       "66889  ['1687686629107', '1687686630650', '1687686632...  [1.68768662e+12]   \n",
       "66890  ['1688194591567', '1688194595574', '1688194602...  [1.68819459e+12]   \n",
       "66891  ['1685715102620', '1685715103191', '1685715104...   [1.6857151e+12]   \n",
       "66892  ['1685715937398', '1685715947273', '1685715958...  [1.68571592e+12]   \n",
       "\n",
       "                   stop                                            appIds0  \\\n",
       "0      [1.68026068e+12]                                         ['4', '6']   \n",
       "1       [1.6802609e+12]  ['6', '6', '6', '6', '6', '6', '6', '6', '6', ...   \n",
       "2      [1.68026094e+12]                                         ['6', '6']   \n",
       "3      [1.68026097e+12]                                              ['6']   \n",
       "4       [1.6802614e+12]  ['6', '6', '6', '6', '6', '6', '6', '6', '6', ...   \n",
       "...                 ...                                                ...   \n",
       "66888  [1.68856761e+12]                                         ['4', '4']   \n",
       "66889  [1.68768686e+12]  ['25', '25', '25', '25', '25', '25', '25', '25...   \n",
       "66890   [1.6881949e+12]  ['4', '36', '36', '36', '36', '36', '36', '36'...   \n",
       "66891  [1.68571531e+12]  ['1', '1', '4', '1', '1', '3', '3', '3', '3', ...   \n",
       "66892  [1.68571624e+12]  ['6', '6', '6', '6', '6', '6', '6', '6', '6', ...   \n",
       "\n",
       "      tapsSession lengthSession                                        partId  \\\n",
       "0             [2]        [1934]  ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   \n",
       "1            [91]       [51590]  ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   \n",
       "2             [2]        [3349]  ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   \n",
       "3             [1]           [0]  ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   \n",
       "4            [34]       [12116]  ['138e7be7ad1a1f6a496c9447ff1dfbde4e8228eb']   \n",
       "...           ...           ...                                           ...   \n",
       "66888         [2]         [507]  ['138e0aa217a29b6e43b191d55547762fb7bc28eb']   \n",
       "66889        [55]      [232127]  ['138e0aa217a29b6e43b191d55547762fb7bc28eb']   \n",
       "66890        [72]      [302195]  ['138e0aa217a29b6e43b191d55547762fb7bc28eb']   \n",
       "66891        [18]      [198617]  ['138e4fc6a0c3f9c84a748783729e965d586628eb']   \n",
       "66892       [230]      [302285]  ['138e4fc6a0c3f9c84a748783729e965d586628eb']   \n",
       "\n",
       "                 timeZone                               tapDeviceId  \\\n",
       "0       ['Europe/Vienna']  ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "1       ['Europe/Vienna']  ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "2       ['Europe/Vienna']  ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "3       ['Europe/Vienna']  ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "4       ['Europe/Vienna']  ['9a5c1517-2f31-4cd4-a5f7-951d0fa29775']   \n",
       "...                   ...                                       ...   \n",
       "66888  ['Asia/Kathmandu']  ['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']   \n",
       "66889  ['Asia/Kathmandu']  ['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']   \n",
       "66890  ['Asia/Kathmandu']  ['aba9995c-d17c-4759-b6fc-bc5f75a1cfe4']   \n",
       "66891     ['Europe/Rome']  ['01e797d4-2d69-4a04-abad-0f53de6eb216']   \n",
       "66892     ['Europe/Rome']  ['01e797d4-2d69-4a04-abad-0f53de6eb216']   \n",
       "\n",
       "                                                category  \\\n",
       "0                                ['-1', 'COMMUNICATION']   \n",
       "1      ['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...   \n",
       "2                     ['COMMUNICATION', 'COMMUNICATION']   \n",
       "3                                      ['COMMUNICATION']   \n",
       "4      ['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...   \n",
       "...                                                  ...   \n",
       "66888                                       ['-1', '-1']   \n",
       "66889  ['SOCIAL', 'SOCIAL', 'SOCIAL', 'SOCIAL', 'SOCI...   \n",
       "66890  ['-1', 'SOCIAL', 'SOCIAL', 'SOCIAL', 'SOCIAL',...   \n",
       "66891  ['PERSONALIZATION', 'PERSONALIZATION', '-1', '...   \n",
       "66892  ['COMMUNICATION', 'COMMUNICATION', 'COMMUNICAT...   \n",
       "\n",
       "                                             application  \n",
       "0                      ['com.miui.home', 'com.whatsapp']  \n",
       "1      ['com.whatsapp', 'com.whatsapp', 'com.whatsapp...  \n",
       "2                       ['com.whatsapp', 'com.whatsapp']  \n",
       "3                                       ['com.whatsapp']  \n",
       "4      ['com.whatsapp', 'com.whatsapp', 'com.whatsapp...  \n",
       "...                                                  ...  \n",
       "66888         ['com.oppo.launcher', 'com.oppo.launcher']  \n",
       "66889  ['com.zhiliaoapp.musically', 'com.zhiliaoapp.m...  \n",
       "66890  ['com.oppo.launcher', 'com.instagram.android',...  \n",
       "66891  ['com.sec.android.app.launcher', 'com.sec.andr...  \n",
       "66892  ['com.whatsapp', 'com.whatsapp', 'com.whatsapp...  \n",
       "\n",
       "[66893 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove empty taps [['', '']]\n",
    "tap_data = tap_data[tap_data['taps'].apply(lambda x: x != \"['']\")].reset_index(drop = True)\n",
    "tap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08b9771-a461-4253-9e06-170d9eed8098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [-1, COMMUNICATION]\n",
       "1        [COMMUNICATION, COMMUNICATION, COMMUNICATION, ...\n",
       "2                           [COMMUNICATION, COMMUNICATION]\n",
       "3                                          [COMMUNICATION]\n",
       "4        [COMMUNICATION, COMMUNICATION, COMMUNICATION, ...\n",
       "                               ...                        \n",
       "66888                                             [-1, -1]\n",
       "66889    [SOCIAL, SOCIAL, SOCIAL, SOCIAL, SOCIAL, SOCIA...\n",
       "66890    [-1, SOCIAL, SOCIAL, SOCIAL, SOCIAL, SOCIAL, S...\n",
       "66891    [PERSONALIZATION, PERSONALIZATION, -1, PERSONA...\n",
       "66892    [COMMUNICATION, COMMUNICATION, COMMUNICATION, ...\n",
       "Name: category, Length: 66893, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to strip external quotes and convert to list \n",
    "def process_entry(entry):\n",
    "    try:\n",
    "        # Remove external quotes and convert to list\n",
    "        entry = entry.strip('\"')\n",
    "        return ast.literal_eval(entry)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Handle malformed entries\n",
    "        #print(f\"Failed to process: {entry}\")\n",
    "        return None\n",
    "\n",
    "#tap_data['application'] = tap_data['application'].apply(process_entry)\n",
    "tap_data['category'] = tap_data['category'].apply(process_entry)\n",
    "tap_data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422199dc-e060-4152-9795-1cb7487085ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [1680260654282, 1680260656216]\n",
       "1        [1680260848742, 1680260849767, 1680260850357, ...\n",
       "2                           [1680260926555, 1680260929904]\n",
       "3                                          [1680260966773]\n",
       "4        [1680261384529, 1680261386184, 1680261386906, ...\n",
       "                               ...                        \n",
       "66888                       [1688567611127, 1688567611634]\n",
       "66889    [1687686629107, 1687686630650, 1687686632048, ...\n",
       "66890    [1688194591567, 1688194595574, 1688194602249, ...\n",
       "66891    [1685715102620, 1685715103191, 1685715104549, ...\n",
       "66892    [1685715937398, 1685715947273, 1685715958539, ...\n",
       "Name: taps, Length: 66893, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tap_data['taps'] = tap_data['taps'].apply(process_entry)\n",
    "tap_data['taps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b2a77d-0ae3-45e0-bbc8-5da97df6367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Applications into list\n",
    "#applications = tap_data['application'].tolist()\n",
    "categories = tap_data['category'].tolist()\n",
    "#categories[0:10]\n",
    "#applications[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a988927-c823-4452-8ba5-18c235b788d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = tap_data['taps'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a61a9720-22c2-47cf-8630-4f82f49b05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lists = list(zip(categories,timestamps))\n",
    "#combined_lists[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01de7346-645e-4ec8-862d-3798f4ddc838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String to Integer Mapping: {'EDUCATION': 0, 'COMMUNICATION': 1, 'HEALTH_AND_FITNESS': 2, 'PHOTOGRAPHY': 3, 'PERSONALIZATION': 4, 'WEATHER': 5, 'LIFESTYLE': 6, 'MEDICAL': 7, 'GAME': 8, 'LIBRARIES_AND_DEMO': 9, 'SPORTS': 10, 'FOOD_AND_DRINK': 11, 'BEAUTY': 12, 'TRAVEL_AND_LOCAL': 13, 'HOUSE_AND_HOME': 14, 'FINANCE': 15, 'EVENTS': 16, None: 17, 'BOOKS_AND_REFERENCE': 18, 'NEWS_AND_MAGAZINES': 19, 'TOOLS': 20, 'VIDEO_PLAYERS': 21, 'MUSIC_AND_AUDIO': 22, 'AUTO_AND_VEHICLES': 23, 'PRODUCTIVITY': 24, '-1': 25, 'PARENTING': 26, 'MAPS_AND_NAVIGATION': 27, 'ART_AND_DESIGN': 28, 'SHOPPING': 29, 'BUSINESS': 30, 'SOCIAL': 31, 'ENTERTAINMENT': 32, 'DATING': 33}\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary of categories and map them to integers\n",
    "\n",
    "# Flatten the list of lists, skipping None sublists\n",
    "flattened_list = [item for sublist in categories if sublist is not None for item in sublist]\n",
    "\n",
    "# Find unique values\n",
    "unique_values = list(set(flattened_list))\n",
    "\n",
    "# Check the length to ensure there are 30 unique elements\n",
    "# print(len(unique_values))  # Should be 30\n",
    "\n",
    "# Assuming unique_values contains your unique categories\n",
    "stoi = {s: i for i, s in enumerate(unique_values)}\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "\n",
    "print(\"String to Integer Mapping:\", stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "103484ba-4a8b-46fa-a43f-29e9729610f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d09450-4c31-4783-9000-2a8286cd2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_itos_stratified_look20.pkl', 'wb') as file:\n",
    "    pk.dump(itos, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76294165-0c10-439e-badf-3a891b42a6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category combination ('low', 'low'): 636 sessions\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('low', 'medium'): 5362 sessions\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "Category combination ('low', 'high'): 16137 sessions\n",
      "    Session tensor shape: torch.Size([28, 34])\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "Category combination ('medium', 'low'): 4689 sessions\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "Category combination ('medium', 'medium'): 11982 sessions\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('medium', 'high'): 6079 sessions\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "Category combination ('high', 'low'): 16750 sessions\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('high', 'medium'): 4730 sessions\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('high', 'high'): 528 sessions\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "    Session tensor shape: torch.Size([3, 34])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'stoi' (string to index mapping) and 'combined_lists' (your data) are defined elsewhere\n",
    "time_bin_size = 60000  # Size of your time bins to represent 1 minute\n",
    "num_categories = len(stoi)  # Number of unique categories\n",
    "\n",
    "# Initialize storage for categorized sessions\n",
    "processed_sessions = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Calculate diversity scores and session durations for each session\n",
    "diversity_scores = []\n",
    "session_durations = []  # To hold session durations\n",
    "for categories, timestamps in combined_lists:\n",
    "    if categories:  # Ensure the categories list is not empty\n",
    "        diversity_score = len(set(categories)) / len(categories)\n",
    "        # Safely convert timestamps to integers, ignoring any invalid entries\n",
    "        timestamps_int = [int(ts) for ts in timestamps if ts.isdigit()]\n",
    "        session_duration = max(timestamps_int) - min(timestamps_int) if timestamps_int else 0\n",
    "    else:\n",
    "        diversity_score = 0  # Handle empty categories list\n",
    "        session_duration = 0\n",
    "    diversity_scores.append(diversity_score)\n",
    "    session_durations.append(session_duration)\n",
    "\n",
    "# Define diversity and duration score thresholds\n",
    "low_diversity_threshold = np.percentile(diversity_scores, 33)\n",
    "high_diversity_threshold = np.percentile(diversity_scores, 66)\n",
    "low_duration_threshold = np.percentile(session_durations, 33)\n",
    "high_duration_threshold = np.percentile(session_durations, 66)\n",
    "\n",
    "# Categorize and process sessions\n",
    "for i, (categories, timestamps) in enumerate(combined_lists):\n",
    "    diversity_score = diversity_scores[i]\n",
    "    session_duration = session_durations[i]\n",
    "\n",
    "    # Determine diversity category\n",
    "    diversity_category = 'low' if diversity_score <= low_diversity_threshold else 'medium' if diversity_score <= high_diversity_threshold else 'high'\n",
    "\n",
    "    # Determine duration category\n",
    "    duration_category = 'low' if session_duration <= low_duration_threshold else 'medium' if session_duration <= high_duration_threshold else 'high'\n",
    "\n",
    "    # Process session\n",
    "    interval_counts = defaultdict(lambda: [0] * num_categories)\n",
    "    timestamps_int = [int(ts) for ts in timestamps if ts.isdigit()]\n",
    "\n",
    "    # Calculate differences between consecutive timestamps for additional analysis\n",
    "    if len(timestamps_int) > 1:\n",
    "        timestamp_diffs = [timestamps_int[i+1] - timestamps_int[i] for i in range(len(timestamps_int)-1)]\n",
    "\n",
    "    for category_item, timestamp in zip(categories, timestamps_int):\n",
    "        if category_item not in stoi:\n",
    "            continue\n",
    "\n",
    "        interval = timestamp // time_bin_size\n",
    "        category_index = stoi[category_item]\n",
    "        interval_counts[interval][category_index] += 1\n",
    "\n",
    "    intervals_sorted = sorted(interval_counts.items())\n",
    "    session_tensor = torch.tensor([counts for _, counts in intervals_sorted], dtype=torch.float)\n",
    "    processed_sessions[diversity_category][duration_category].append(session_tensor)\n",
    "\n",
    "# Print the contents of processed_sessions to check the lists\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        category_combination = (diversity_category, duration_category)\n",
    "        sessions_list = processed_sessions[diversity_category][duration_category]\n",
    "        print(f\"Category combination {category_combination}: {len(sessions_list)} sessions\")\n",
    "        for session_tensor in sessions_list[:2]:  # Limit output for demonstration\n",
    "            print(f\"    Session tensor shape: {session_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61f330-4d7d-4745-8ec8-2ba99181e179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e23599-5345-426c-a393-6ab8a85cce8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fc22a-6a14-4fd8-bf59-e8775af2f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "time_bin_size = 1000  # Define the size of your time bins\n",
    "num_categories = len(stoi)  # Number of unique categories\n",
    "\n",
    "# Calculate diversity scores for each session\n",
    "diversity_scores = []\n",
    "for categories, _ in combined_lists:\n",
    "    if categories:  # Ensure the categories list is not empty\n",
    "        diversity_score = len(set(categories)) / len(categories)\n",
    "    else:\n",
    "        diversity_score = 0  # Handle empty categories list\n",
    "    diversity_scores.append(diversity_score)\n",
    "\n",
    "# Define diversity score thresholds for categorizing sessions\n",
    "low_diversity_threshold = np.percentile(diversity_scores, 33)\n",
    "high_diversity_threshold = np.percentile(diversity_scores, 66)\n",
    "\n",
    "# Categorize sessions based on their diversity scores\n",
    "sessions_categories = {'low': [], 'medium': [], 'high': []}\n",
    "for i, (categories, timestamps) in enumerate(combined_lists):\n",
    "    score = diversity_scores[i]\n",
    "    len = \n",
    "    if score <= low_diversity_threshold:\n",
    "        category = 'low'\n",
    "    elif score <= high_diversity_threshold:\n",
    "        category = 'medium'\n",
    "    else:\n",
    "        category = 'high'\n",
    "    sessions_categories[category].append((categories, timestamps))\n",
    "\n",
    "# Now, let's integrate your existing code here to process the categorized sessions\n",
    "# For simplicity, I'll process all sessions but in a real scenario, you'd sample as described previously\n",
    "processed_sessions = {'low': [], 'medium': [], 'high': []}\n",
    "\n",
    "for diversity_group in sessions_categories:  # Use 'diversity_group' instead of 'category'\n",
    "    for categories, timestamps in sessions_categories[diversity_group]:\n",
    "        interval_counts = defaultdict(lambda: [0] * num_categories)\n",
    "        \n",
    "        for category_item, timestamp in zip(categories, timestamps):  # Use 'category_item' to avoid conflict\n",
    "            if category_item not in stoi or timestamp == '':\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                interval = int(timestamp) // time_bin_size\n",
    "            except ValueError:\n",
    "                continue\n",
    "            \n",
    "            category_index = stoi[category_item]  # Use 'category_item' here\n",
    "            interval_counts[interval][category_index] += 1\n",
    "        \n",
    "        intervals_sorted = sorted(interval_counts.items())\n",
    "        session_tensor = torch.tensor([counts for _, counts in intervals_sorted], dtype=torch.float)\n",
    "        processed_sessions[diversity_group].append(session_tensor)  # Use 'diversity_group' here\n",
    "\n",
    "\n",
    "# At this point, 'processed_sessions' contains tensors categorized into 'low', 'medium', and 'high'\n",
    "# diversity groups. You can now sample from these groups to balance your datasets for training, development, and testing.\n",
    "\n",
    "# The next steps would involve sampling from 'processed_sessions' as described earlier.\n",
    "# This is left as an exercise based on your specific requirements for dataset sizes and proportions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38dc6f66-76b8-44b0-8181-b73f00a1305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category combination ('low', 'low'): 636 sessions\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('low', 'medium'): 5362 sessions\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "Category combination ('low', 'high'): 16137 sessions\n",
      "    Session tensor shape: torch.Size([28, 34])\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "Category combination ('medium', 'low'): 4689 sessions\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "Category combination ('medium', 'medium'): 11982 sessions\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('medium', 'high'): 6079 sessions\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "Category combination ('high', 'low'): 16750 sessions\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('high', 'medium'): 4730 sessions\n",
      "    Session tensor shape: torch.Size([2, 34])\n",
      "    Session tensor shape: torch.Size([1, 34])\n",
      "Category combination ('high', 'high'): 528 sessions\n",
      "    Session tensor shape: torch.Size([3, 34])\n",
      "    Session tensor shape: torch.Size([3, 34])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'stoi' (string to index mapping) and 'combined_lists' (your data) are defined elsewhere\n",
    "time_bin_size = 60000  #size of your time bins to represent 1 minute\n",
    "num_categories = len(stoi)  # Number of unique categories\n",
    "\n",
    "# Calculate diversity scores and session durations for each session\n",
    "diversity_scores = []\n",
    "session_durations = []  # To hold session durations\n",
    "for categories, timestamps in combined_lists:\n",
    "    if categories:  # Ensure the categories list is not empty\n",
    "        diversity_score = len(set(categories)) / len(categories)\n",
    "        # Safely convert timestamps to integers, ignoring any invalid entries\n",
    "        timestamps_int = [int(ts) for ts in timestamps if ts.isdigit()]\n",
    "        session_duration = max(timestamps_int) - min(timestamps_int) if timestamps_int else 0\n",
    "    else:\n",
    "        diversity_score = 0  # Handle empty categories list\n",
    "        session_duration = 0\n",
    "    diversity_scores.append(diversity_score)\n",
    "    session_durations.append(session_duration)\n",
    "\n",
    "# Define diversity and duration score thresholds\n",
    "low_diversity_threshold = np.percentile(diversity_scores, 33)\n",
    "high_diversity_threshold = np.percentile(diversity_scores, 66)\n",
    "low_duration_threshold = np.percentile(session_durations, 33)\n",
    "high_duration_threshold = np.percentile(session_durations, 66)\n",
    "\n",
    "# Initialize storage for categorized sessions\n",
    "processed_sessions = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Categorize and process sessions\n",
    "for i, (categories, timestamps) in enumerate(combined_lists):\n",
    "    diversity_score = diversity_scores[i]\n",
    "    session_duration = session_durations[i]\n",
    "    \n",
    "    # Determine diversity category\n",
    "    if diversity_score <= low_diversity_threshold:\n",
    "        diversity_category = 'low'\n",
    "    elif diversity_score <= high_diversity_threshold:\n",
    "        diversity_category = 'medium'\n",
    "    else:\n",
    "        diversity_category = 'high'\n",
    "\n",
    "    # Determine duration category\n",
    "    if session_duration <= low_duration_threshold:\n",
    "        duration_category = 'low'\n",
    "    elif session_duration <= high_duration_threshold:\n",
    "        duration_category = 'medium'\n",
    "    else:\n",
    "        duration_category = 'high'\n",
    "\n",
    "    # Process session\n",
    "    interval_counts = defaultdict(lambda: [0] * num_categories)\n",
    "    timestamps_int = [int(ts) for ts in timestamps if ts.isdigit()]  # Safe conversion again for processing\n",
    "    for category_item, timestamp in zip(categories, timestamps_int):\n",
    "        if category_item not in stoi:\n",
    "            continue\n",
    "        \n",
    "        interval = timestamp // time_bin_size\n",
    "        category_index = stoi[category_item]\n",
    "        interval_counts[interval][category_index] += 1\n",
    "\n",
    "    intervals_sorted = sorted(interval_counts.items())\n",
    "    session_tensor = torch.tensor([counts for _, counts in intervals_sorted], dtype=torch.float)\n",
    "    processed_sessions[diversity_category][duration_category].append(session_tensor)\n",
    "\n",
    "# Print the contents of processed_sessions to check the 9 lists\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        category_combination = (diversity_category, duration_category)\n",
    "        sessions_list = processed_sessions[diversity_category][duration_category]\n",
    "        print(f\"Category combination {category_combination}: {len(sessions_list)} sessions\")\n",
    "        # Optional: Print details of each session tensor for the first few sessions in each category\n",
    "        for session_tensor in sessions_list[:2]:  # Adjust as needed to limit output\n",
    "            print(f\"    Session tensor shape: {session_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792ea5c-109f-4ee3-8cd0-4d51569313ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "71171e3f-de88-4683-9e6b-ebb959adbc56",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Determine the minimum number of sessions in any diversity category\n",
    "min_sessions = min(len(processed_sessions['low']), len(processed_sessions['medium']), len(processed_sessions['high']))\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample sessions for training, development, and testing sets\n",
    "training_sessions, development_sessions, testing_sessions = [], [], []\n",
    "\n",
    "# Define proportions for splitting: 80% training, 10% development, 10% testing\n",
    "train_split = int(min_sessions * 0.8)\n",
    "dev_split = int(min_sessions * 0.1)\n",
    "\n",
    "# Randomly shuffle and sample sessions from each diversity category\n",
    "for category in processed_sessions:\n",
    "    np.random.shuffle(processed_sessions[category])\n",
    "    training_sessions.extend(processed_sessions[category][:train_split])\n",
    "    development_sessions.extend(processed_sessions[category][train_split:train_split + dev_split])\n",
    "    testing_sessions.extend(processed_sessions[category][train_split + dev_split:min_sessions])\n",
    "\n",
    "print(f\"Training sessions count: {len(training_sessions)}\")\n",
    "print(f\"Development sessions count: {len(development_sessions)}\")\n",
    "print(f\"Testing sessions count: {len(testing_sessions)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71f5a5-b14c-4b1e-9095-ce6ebe57221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#50th Percentile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Instead of using the minimum number of sessions, use a percentile to determine the sample size\n",
    "# This allows for more sessions to be included from each category\n",
    "sample_size_per_category = int(np.percentile(\n",
    "    [len(processed_sessions[div][dur]) for div in ['low', 'medium', 'high'] for dur in ['low', 'medium', 'high']],\n",
    "    50  # Adjust the percentile as needed to balance between data utilization and balance\n",
    "))\n",
    "\n",
    "# Define proportions for splitting: 80% training, 10% development, 10% testing\n",
    "train_split = int(sample_size_per_category * 0.8)\n",
    "dev_split = int(sample_size_per_category * 0.1)\n",
    "\n",
    "training_sessions, development_sessions, testing_sessions = [], [], []\n",
    "\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        sessions = processed_sessions[diversity_category][duration_category]\n",
    "        np.random.shuffle(sessions)\n",
    "        sessions_sampled = sessions[:sample_size_per_category]  # Sample based on the determined size\n",
    "        training_sessions.extend(sessions_sampled[:train_split])\n",
    "        development_sessions.extend(sessions_sampled[train_split:train_split + dev_split])\n",
    "        testing_sessions.extend(sessions_sampled[train_split + dev_split:sample_size_per_category])\n",
    "\n",
    "print(f\"Training sessions count: {len(training_sessions)}\")\n",
    "print(f\"Development sessions count: {len(development_sessions)}\")\n",
    "print(f\"Testing sessions count: {len(testing_sessions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59858a2f-63a2-4f7d-b100-09df81dbb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDERSAMPLING\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Find the minimum number of sessions across all categories\n",
    "min_sessions_size = min(\n",
    "    [len(processed_sessions[div][dur]) for div in ['low', 'medium', 'high'] for dur in ['low', 'medium', 'high']]\n",
    ")\n",
    "\n",
    "# Use the minimum size for a balanced sample size across categories\n",
    "sample_size_per_category = min_sessions_size\n",
    "\n",
    "# Define proportions for splitting: 80% training, 10% development, 10% testing\n",
    "train_split = int(sample_size_per_category * 0.8)\n",
    "dev_split = int(sample_size_per_category * 0.1)\n",
    "# The rest is for testing, ensuring we use all data in the split\n",
    "\n",
    "training_sessions, development_sessions, testing_sessions = [], [], []\n",
    "\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        sessions = processed_sessions[diversity_category][duration_category]\n",
    "        np.random.shuffle(sessions)\n",
    "        # Sample based on the determined minimum size\n",
    "        sessions_sampled = sessions[:sample_size_per_category]\n",
    "        training_sessions.extend(sessions_sampled[:train_split])\n",
    "        development_sessions.extend(sessions_sampled[train_split:train_split + dev_split])\n",
    "        testing_sessions.extend(sessions_sampled[train_split + dev_split:])\n",
    "\n",
    "print(f\"Training sessions count: {len(training_sessions)}\")\n",
    "print(f\"Development sessions count: {len(development_sessions)}\")\n",
    "print(f\"Testing sessions count: {len(testing_sessions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de5461-e91c-4b4b-b3ac-d393d0f60e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OVERSAMPLING\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming processed_sessions is defined and is a dict of dicts of lists\n",
    "# Calculate sizes for all categories\n",
    "category_sizes = {\n",
    "    (div, dur): len(processed_sessions[div][dur])\n",
    "    for div in ['low', 'medium', 'high'] for dur in ['low', 'medium', 'high']\n",
    "}\n",
    "\n",
    "# Find the maximum size to aim for oversampling\n",
    "max_size = max(category_sizes.values())\n",
    "\n",
    "training_sessions, development_sessions, testing_sessions = [], [], []\n",
    "\n",
    "for div, dur in category_sizes:\n",
    "    sessions = processed_sessions[div][dur]\n",
    "    np.random.shuffle(sessions)\n",
    "    \n",
    "    # Manually repeat the sessions to approximate oversampling\n",
    "    oversampled_sessions = []\n",
    "    while len(oversampled_sessions) < max_size:\n",
    "        oversampled_sessions.extend(sessions)\n",
    "    oversampled_sessions = oversampled_sessions[:max_size]\n",
    "    \n",
    "    # Splitting sessions\n",
    "    train_split = int(len(oversampled_sessions) * 0.8)\n",
    "    dev_split = int(len(oversampled_sessions) * 0.1)\n",
    "    \n",
    "    training_sessions.extend(oversampled_sessions[:train_split])\n",
    "    development_sessions.extend(oversampled_sessions[train_split:train_split + dev_split])\n",
    "    testing_sessions.extend(oversampled_sessions[train_split + dev_split:])\n",
    "\n",
    "print(f\"Training sessions count: {len(training_sessions)}\")\n",
    "print(f\"Development sessions count: {len(development_sessions)}\")\n",
    "print(f\"Testing sessions count: {len(testing_sessions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f0bf9ae-6cc3-494b-99c8-c8810e9d3098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3141\n",
      "Development set size: 450\n",
      "Testing set size: 909\n"
     ]
    }
   ],
   "source": [
    "# STRATIFICATION\n",
    "\n",
    "from random import sample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.2\n",
    "dev_ratio = 0.1\n",
    "\n",
    "# Storage for stratified splits\n",
    "stratified_train = []\n",
    "stratified_dev = []\n",
    "stratified_test = []\n",
    "session_all = []\n",
    "# Stratify and split data\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        sessions_all = processed_sessions[diversity_category][duration_category]\n",
    "        sessions = sample(sessions_all, min(len(sessions_all), 500))  # Corrected typo and ensured not to exceed list size\n",
    "\n",
    "        \n",
    "        # Check if there are sessions to split\n",
    "        if len(sessions) > 0:\n",
    "            # Split sessions into training and temp (temporary holding the rest)\n",
    "            sessions_train, sessions_temp = train_test_split(sessions, test_size=(1 - train_ratio), random_state=42)\n",
    "            \n",
    "            # Split the temp into development and testing\n",
    "            sessions_dev, sessions_test = train_test_split(sessions_temp, test_size=(test_ratio / (test_ratio + dev_ratio)), random_state=42)\n",
    "            \n",
    "            # Append to respective stratified sets\n",
    "            stratified_train.extend(sessions_train)\n",
    "            stratified_dev.extend(sessions_dev)\n",
    "            stratified_test.extend(sessions_test)\n",
    "\n",
    "# Now, stratified_train, stratified_dev, and stratified_test contain your stratified splits\n",
    "print(f\"Training set size: {len(stratified_train)}\")\n",
    "print(f\"Development set size: {len(stratified_dev)}\")\n",
    "print(f\"Testing set size: {len(stratified_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69840fd7-7a96-46e6-9415-7e1e5b01afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 53511\n",
      "Development set size: 6690\n",
      "Testing set size: 6692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "dev_ratio = 0.1\n",
    "\n",
    "# Storage for stratified splits\n",
    "stratified_train = []\n",
    "stratified_dev = []\n",
    "stratified_test = []\n",
    "\n",
    "# Stratify and split data\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        # Directly use all sessions without sampling up to 500\n",
    "        sessions_all = processed_sessions[diversity_category][duration_category]\n",
    "        \n",
    "        # Check if there are sessions to split\n",
    "        if len(sessions_all) > 0:\n",
    "            # Split sessions into training and temp (temporary holding the rest)\n",
    "            sessions_train, sessions_temp = train_test_split(sessions_all, test_size=(1 - train_ratio), random_state=42)\n",
    "            \n",
    "            # Split the temp into development and testing\n",
    "            sessions_dev, sessions_test = train_test_split(sessions_temp, test_size=(test_ratio / (test_ratio + dev_ratio)), random_state=42)\n",
    "            \n",
    "            # Append to respective stratified sets\n",
    "            stratified_train.extend(sessions_train)\n",
    "            stratified_dev.extend(sessions_dev)\n",
    "            stratified_test.extend(sessions_test)\n",
    "\n",
    "print(f\"Training set size: {len(stratified_train)}\")\n",
    "print(f\"Development set size: {len(stratified_dev)}\")\n",
    "print(f\"Testing set size: {len(stratified_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1da17e5d-2252-4b47-87e4-0e527c577005",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dict_strat = {\n",
    "    'train_sessions': stratified_train,\n",
    "    'test_sessions': stratified_test,\n",
    "    'dev_sessions': stratified_dev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ee243fa-dc5e-41c2-83b7-8644cbde5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LSTM_time1min_stratified_20lookback.pkl', 'wb') as file:\n",
    "    pk.dump(tensor_dict_strat, file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd030f31-41f5-46f2-b48a-6dc24acf7c7c",
   "metadata": {},
   "source": [
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "\n",
    "#combined_lists is a list of two lists: one for categories and one for timestamps\n",
    "# stoi is a mapping from categories to indices\n",
    "\n",
    "time_bin_size = 1000  # Define the size of your time bins\n",
    "num_categories = len(stoi)  # Number of unique categories\n",
    "\n",
    "sessions = []\n",
    "\n",
    "# Convert timestamps to intervals and count category occurrences in each interval\n",
    "for categories, timestamps in combined_lists:\n",
    "    interval_counts = defaultdict(lambda: [0] * num_categories)  # Default to zero counts for each category\n",
    "    \n",
    "    for category, timestamp in zip(categories, timestamps):\n",
    "        # Skip categories not in stoi or empty timestamps\n",
    "        if category not in stoi or timestamp == '':\n",
    "            continue  \n",
    "        \n",
    "        try:\n",
    "            interval = int(timestamp) // time_bin_size  # Determine the interval for this timestamp\n",
    "        except ValueError:\n",
    "            # Handle other invalid timestamp formats if necessary\n",
    "            continue\n",
    "        \n",
    "        category_index = stoi[category]  # Get the index for this category\n",
    "        interval_counts[interval][category_index] += 1  # Increment count for this category in this interval\n",
    "    \n",
    "    # Convert interval_counts to a sorted list of intervals and their counts\n",
    "    intervals_sorted = sorted(interval_counts.items())\n",
    "    \n",
    "    # Create a tensor for this session, with shape [time intervals, num_categories]\n",
    "    session_tensor = torch.tensor([counts for _, counts in intervals_sorted], dtype=torch.float)\n",
    "    sessions.append(session_tensor)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9ccc158-26c7-49df-964c-a24fe7400765",
   "metadata": {},
   "source": [
    "# Calculate the sizes of the splits\n",
    "total_sessions = len(sessions)\n",
    "train_size = int(0.8 * total_sessions)\n",
    "test_size = int(0.1 * total_sessions)\n",
    "# The remaining for development; ensures all data is used even if not perfectly divisible\n",
    "\n",
    "# Split the sessions\n",
    "train_sessions = sessions[:train_size]\n",
    "test_sessions = sessions[train_size:train_size + test_size]\n",
    "dev_sessions = sessions[train_size + test_size:]\n",
    "\n",
    "# Verify the splits\n",
    "print(f\"Total sessions: {total_sessions}\")\n",
    "print(f\"Training sessions: {len(train_sessions)}\")\n",
    "print(f\"Test sessions: {len(test_sessions)}\")\n",
    "print(f\"Development sessions: {len(dev_sessions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27599a43-b5e9-4fc6-a654-5e5ee346e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dict = {\n",
    "    'train_sessions': training_sessions,\n",
    "    'test_sessions': testing_sessions,\n",
    "    'dev_sessions': development_sessions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7ee5f-2c54-40d3-90b7-bfd964a6b568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed60ce2-b16b-4712-9460-84ca717d15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LSTM_time1min_stratified_500samples_10sec.pkl', 'wb') as file:\n",
    "    pk.dump(tensor_dict_strat, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b763e-4f81-4f14-b85c-dc9fce08ab34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69226652-5529-4bac-a249-9a215cc3ff4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f170ee-f8fd-4f51-b401-22accebd13fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0e503-0174-4f7c-b3cd-a511f917c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assumed existing variables and data structures: processed_sessions, stoi\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "dev_ratio = 0.1\n",
    "\n",
    "# Storage for stratified and oversampled splits\n",
    "stratified_train = defaultdict(lambda: defaultdict(list))\n",
    "stratified_dev = defaultdict(lambda: defaultdict(list))\n",
    "stratified_test = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Function to oversample within each stratified category\n",
    "def oversample_sessions(sessions_dict):\n",
    "    max_size = max(len(sessions) for category in sessions_dict.values() for sessions in category.values())\n",
    "    for diversity_category in sessions_dict:\n",
    "        for duration_category in sessions_dict[diversity_category]:\n",
    "            sessions = sessions_dict[diversity_category][duration_category]\n",
    "            while len(sessions) < max_size:\n",
    "                oversampled_sessions = [session.clone() for session in sessions]  # Clone to avoid altering original tensors\n",
    "                sessions.extend(oversampled_sessions[:max_size - len(sessions)])\n",
    "            sessions_dict[diversity_category][duration_category] = sessions\n",
    "\n",
    "# Stratify and split data\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        sessions_all = processed_sessions[diversity_category][duration_category]\n",
    "        if not sessions_all:\n",
    "            continue  # Skip if no sessions in this category\n",
    "\n",
    "        # Split sessions into training, dev, and test\n",
    "        sessions_train, sessions_temp = train_test_split(sessions_all, test_size=(1 - train_ratio), random_state=42)\n",
    "        sessions_dev, sessions_test = train_test_split(sessions_temp, test_size=(test_ratio / (test_ratio + dev_ratio)), random_state=42)\n",
    "        \n",
    "        # Store sessions\n",
    "        stratified_train[diversity_category][duration_category] = sessions_train\n",
    "        stratified_dev[diversity_category][duration_category] = sessions_dev\n",
    "        stratified_test[diversity_category][duration_category] = sessions_test\n",
    "\n",
    "# Apply oversampling to the training set after the function definition\n",
    "oversample_sessions(stratified_train)\n",
    "\n",
    "# Aggregate sessions from each stratified split into separate lists\n",
    "def aggregate_sessions(stratified_sessions):\n",
    "    aggregated_sessions = []\n",
    "    for diversity_category in stratified_sessions:\n",
    "        for duration_category in stratified_sessions[diversity_category]:\n",
    "            aggregated_sessions.extend(stratified_sessions[diversity_category][duration_category])\n",
    "    return aggregated_sessions\n",
    "\n",
    "# Aggregate training, testing, and development sessions\n",
    "training_sessions = aggregate_sessions(stratified_train)\n",
    "testing_sessions = aggregate_sessions(stratified_test)\n",
    "development_sessions = aggregate_sessions(stratified_dev)\n",
    "\n",
    "# Combine aggregated sessions into a single dictionary\n",
    "tensor_dict = {\n",
    "    'train_sessions': training_sessions,\n",
    "    'test_sessions': testing_sessions,\n",
    "    'dev_sessions': development_sessions\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7831b50-5214-46aa-b2e8-57e609a20624",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a1426-fb82-4516-b259-e72934e87f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data_time1min_stratified_oversampled.pkl', 'wb') as file:\n",
    "    pk.dump(tensor_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a52ef-baeb-489f-8f36-aca534b384ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from random import choices\n",
    "\n",
    "\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.2\n",
    "dev_ratio = 0.1\n",
    "\n",
    "# Storage for stratified splits\n",
    "stratified_train = []\n",
    "stratified_dev = []\n",
    "stratified_test = []\n",
    "\n",
    "# Placeholder for categories associated with each session in stratified_train\n",
    "session_categories = []\n",
    "\n",
    "# Stratify and split data\n",
    "for diversity_category in ['low', 'medium', 'high']:\n",
    "    for duration_category in ['low', 'medium', 'high']:\n",
    "        sessions_all = processed_sessions[diversity_category][duration_category]\n",
    "        sessions = sample(sessions_all, min(len(sessions_all), 500))  # Sample up to 500 sessions\n",
    "\n",
    "        # Split sessions into training and temp (holding the rest)\n",
    "        sessions_train, sessions_temp = train_test_split(sessions, test_size=(1 - train_ratio), random_state=42)\n",
    "        sessions_dev, sessions_test = train_test_split(sessions_temp, test_size=(test_ratio / (test_ratio + dev_ratio)), random_state=42)\n",
    "        \n",
    "        # Append sessions and their categories to respective lists\n",
    "        stratified_train.extend(sessions_train)\n",
    "        stratified_dev.extend(sessions_dev)\n",
    "        stratified_test.extend(sessions_test)\n",
    "        session_categories.extend([f\"{diversity_category}-{duration_category}\"] * len(sessions_train))\n",
    "\n",
    "\n",
    "def dynamic_oversample_sessions(sessions, categories):\n",
    "    category_counts = Counter(categories)\n",
    "    max_count = max(category_counts.values())\n",
    "    \n",
    "    # Organize sessions by category\n",
    "    sessions_by_category = defaultdict(list)\n",
    "    for session, category in zip(sessions, categories):\n",
    "        sessions_by_category[category].append(session)\n",
    "    \n",
    "    # Oversample sessions in each category\n",
    "    oversampled_sessions = []\n",
    "    for category, sessions in sessions_by_category.items():\n",
    "        required_additional = max_count - len(sessions)\n",
    "        # Using random.choices for oversampling\n",
    "        oversampled = sessions + choices(sessions, k=required_additional)\n",
    "        oversampled_sessions.extend(oversampled)\n",
    "    \n",
    "    return oversampled_sessions\n",
    "\n",
    "# Now apply dynamic oversampling with the corrected function\n",
    "oversampled_train = dynamic_oversample_sessions(stratified_train, session_categories)\n",
    "\n",
    "# Update stratified_train with oversampled data\n",
    "stratified_train = oversampled_train\n",
    "\n",
    "print(f\"Training set size after oversampling: {len(stratified_train)}\")\n",
    "print(f\"Development set size: {len(stratified_dev)}\")\n",
    "print(f\"Testing set size: {len(stratified_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a1533-af73-4cb5-aae0-da177c954f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def dynamic_oversample_sessions(sessions, categories):\n",
    "    category_counts = Counter(categories)\n",
    "    max_count = max(category_counts.values())\n",
    "    \n",
    "    print(f\"Original category counts: {category_counts}\")\n",
    "    print(f\"Target max count for oversampling: {max_count}\")\n",
    "    \n",
    "    # Organize sessions by category\n",
    "    sessions_by_category = defaultdict(list)\n",
    "    for session, category in zip(sessions, categories):\n",
    "        sessions_by_category[category].append(session)\n",
    "    \n",
    "    oversampled_sessions = []\n",
    "    for category, sessions in sessions_by_category.items():\n",
    "        required_additional = max_count - len(sessions)\n",
    "        oversampled = sessions + choices(sessions, k=required_additional)\n",
    "        oversampled_sessions.extend(oversampled)\n",
    "        print(f\"Category: {category}, Original: {len(sessions)}, Oversampled: {len(oversampled)}\")\n",
    "    \n",
    "    return oversampled_sessions\n",
    "\n",
    "# Apply dynamic oversampling\n",
    "oversampled_train = dynamic_oversample_sessions(stratified_train, session_categories)\n",
    "\n",
    "# Update stratified_train with oversampled data\n",
    "stratified_train = oversampled_train\n",
    "\n",
    "print(f\"\\nTraining set size after oversampling: {len(stratified_train)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
